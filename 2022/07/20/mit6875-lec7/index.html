<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>「Cryptography-MIT6875」: Lecture 7 - fred&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="fred&#039;s blog"><meta name="msapplication-TileImage" content="/img/heart.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="fred&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="In this series, I will learn MIT 6.875, Foundations of Cryptography, lectured by Vinod Vaikuntanathan. Any corrections and advice are welcome. ^ - ^    It is indeed possible for $F(x)$ to leak a lo"><meta property="og:type" content="blog"><meta property="og:title" content="「Cryptography-MIT6875」: Lecture 7"><meta property="og:url" content="https://f7ed.com/2022/07/20/mit6875-lec7/"><meta property="og:site_name" content="fred&#039;s blog"><meta property="og:description" content="In this series, I will learn MIT 6.875, Foundations of Cryptography, lectured by Vinod Vaikuntanathan. Any corrections and advice are welcome. ^ - ^    It is indeed possible for $F(x)$ to leak a lo"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://f7ed.com/gallery/thumbnails/mit6875-lec7-thumbnial.png"><meta property="article:published_time" content="2022-07-19T16:00:00.000Z"><meta property="article:modified_time" content="2022-08-12T04:33:02.861Z"><meta property="article:author" content="f7ed"><meta property="article:tag" content="OWF"><meta property="article:tag" content="OWP"><meta property="article:tag" content="HCB"><meta property="article:tag" content="GL Theorem"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/thumbnails/mit6875-lec7-thumbnial.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://f7ed.com/2022/07/20/mit6875-lec7/"},"headline":"「Cryptography-MIT6875」: Lecture 7","image":["https://f7ed.com/gallery/thumbnails/mit6875-lec7-thumbnial.png"],"datePublished":"2022-07-19T16:00:00.000Z","dateModified":"2022-08-12T04:33:02.861Z","author":{"@type":"Person","name":"f7ed"},"publisher":{"@type":"Organization","name":"fred's blog","logo":{"@type":"ImageObject","url":"https://f7ed.com/img/f1ed_logo.png"}},"description":"In this series, I will learn MIT 6.875, Foundations of Cryptography, lectured by Vinod Vaikuntanathan. Any corrections and advice are welcome. ^ - ^    It is indeed possible for $F(x)$ to leak a lo"}</script><link rel="canonical" href="https://f7ed.com/2022/07/20/mit6875-lec7/"><link rel="icon" href="/img/heart.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-M5KG3CQTSF" async></script><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-M5KG3CQTSF');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="fred's blog" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/f1ed_logo.png" alt="fred&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/liu">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/f7ed"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-bars"></i>「Cryptography-MIT6875」: Lecture 7</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2022-07-19T16:00:00.000Z" title="2022-07-19T16:00:00.000Z">2022-07-20</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2022-08-12T04:33:02.861Z" title="2022-08-12T04:33:02.861Z">2022-08-12</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Cryptography-MIT6875/">Cryptography-MIT6875</a></span><span class="level-item"><i class="far fa-clock"></i> 35 minutes read (About 5292 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><article class="message message-immersive is-info">
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="message-body">
<i class="fas fa-info-circle mr-2"></i>
In this <a href="/categories/Cryptography-MIT6875">series</a>, I will learn MIT 6.875, <strong>Foundations of Cryptography</strong>, lectured by <strong>Vinod Vaikuntanathan</strong>.
<br>Any corrections and advice are welcome. ^ - ^
</div>
</article>

<p>It is indeed possible for $F(x)$ to leak a lot of information about $x$ even if $F$ is one-way.</p>
<p>The <strong>hardcore predicate</strong> $B(x)$ represent the specific piece of information about $x$ which is hard to compute given $F(x)$.</p>
<p><font color=blue><u><b>Topics Covered: </b></u></font> </p>
<ul>
<li>Definition of one-way functions (OWF)</li>
<li>Definition of hardcore bit/predicate (HCB)</li>
<li>One-way permutations → PRG.<br>(In fact, one-way functions → PRG, but that’s a much harder theorem.)</li>
<li>Goldreich-Levin Theorem: every OWF has a HCB.<br>(Proof for an important special case.)</li>
</ul>
<span id="more"></span>

<h1 id="One-way-Functions"><a href="#One-way-Functions" class="headerlink" title="One-way Functions"></a>One-way Functions</h1><p>Informally, one-way function is easy to compute and hard to invert.</p>
<img src="https://s1.ax1x.com/2022/07/23/jXsCHU.png" alt="OWF" style="zoom:43%;" />

<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>In last blog, we introduced briefly the definition of One-way functions.</p>
<p><font color=blue><u><b>Take 1 (Not a useful definition): </b></u></font> </p>
<p>A function (family) $\{F_n\}_{n\in \mathbb{N}}$ where $F_n:\{0,1\}^n\rightarrow \{0,1\}^{m(n)}$  <strong>is one-way</strong> if for every <strong>p.p.t.</strong> adversary $A$, there is a <strong>negligible</strong> function $\mu$ s.t.</p>

$$
\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F_n(x):A(1^n,y)=x]\le \mu(n)
$$



<p>Consider $F_n(x)=0$ for all $x$. </p>
<p>This is one-way according to the above definition. But it’s impossible to find <strong>the inverse</strong> even if $A$ <u>has unbounded time.</u></p>
<p>The probability of guessing the inverse of $0$ is negligible since it is essentially random. But $f(x)=0$ is <strong>not</strong> one-way function obviously.</p>
<p>Hence, it’s not a useful or meaningful definition.</p>
<p>The <strong>right definition</strong> should be that <u>it is impossible to find an inverse</u> in p.p.t. rather than the exactly chosen $x$.</p>
 <article class="message is-info"> <div class="message-header"> 

<p><strong>One-way Functions Definition:</strong></p>
 </div> <div class="message-body"> 

<p>A function (family) $\{F_n\}_{n\in \mathbb{N}}$ where $F_n:\{0,1\}^n\rightarrow \{0,1\}^{m(n)}$  <strong>is one-way</strong> if for every <strong>p.p.t.</strong> adversary $A$, there is a <strong>negligible</strong> function $\mu$ s.t.</p>

$$
\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F_n(x):A(1^n,y)=\color{red}{x':y=F_n(x')}]\le \mu(n)
$$



 </div> </article> 

<p>I’m not going to ask the adversary to come up with $x$ itself which may be impossible. </p>
<p>Instead, I’m just going to ask the <strong>adversary</strong> to <u>come up with an $x’$ such that $y$ is equal to $F(x’)$.</u> It’s sort of the pre-image of $y$.</p>
<p>Hence, the adversary can always find an inverse <u>with unbounded time.</u></p>
<p>But it should <strong>be hard</strong> <u>with probabilistic polynomial time.</u></p>
<hr>
<p>Moreover, <strong>One-way Permutations</strong> are <u>one-to-one</u> one-way functions with $m(n)=n$.</p>
<h1 id="Hardcore-Bits"><a href="#Hardcore-Bits" class="headerlink" title="Hardcore Bits"></a>Hardcore Bits</h1><p>If $F$ is a one-way function, it’s <strong>hard to compute a pre-image</strong> of $F(x)$ for a randomly chosen $x$.</p>
<p>How about computing <strong>partial information</strong> about an inverse ?</p>
<p>We saw in last blog that we can tell efficiently if $h$ is quadratic residue.</p>
<p>So for the discrete log function $x=\operatorname{dlog}_g(h)$, <u>computing the least significant bit(LSB)</u> of $x$ is <strong>easy</strong>. </p>
<p>But <u>MSB</u> turns out to be <strong>hard</strong>.</p>
<p>Moreover, there are <strong>one-way functions</strong> for which it is <u>easy to compute the first half of the bits</u> of the inverse.</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> <strong>One-way function family easy to compute the first half of the bits:</strong>

<p>There is an obvious fact that if $f(x)$ is one-way, then $f’(r||x)=r||f(x)$ is one-way. ($|r|=|f(x)|$)<br>It’s hard to compute the pre-image of $f’(r||x)$ because if you can break $f’$ then you can break $f$.<br>But it’s easy to compute the first half of the bits since they are written in the output.</p>
 </div> </article> 

<p>Nevertheless, there has to <strong>be a hardcore set of hard</strong> to invert inputs.</p>
<p>Concretely, dose there necessarily <strong>exist some bit</strong> of $x$ that is hard to compute ?</p>
<p>Particularly, “<u>hard to compute</u>” means “<u>hard to guess with probability non-negligibly better than 1/2</u>” since any bit can be guessed correctly with probability 1/2.</p>
<p>So dose there necessarily <strong>exist some bit</strong> of $x$ that is hard to guess with probability non-negligibly better than 1/2 ?</p>
<h2 id="Hardcore-Bit-Def"><a href="#Hardcore-Bit-Def" class="headerlink" title="Hardcore Bit Def"></a>Hardcore Bit Def</h2><p><font color=blue><u><b>Hardcore Bit Definition (Take 1):</b></u></font> </p>
<p>For any function (family) $F:\{0,1\}^n\rightarrow \{0,1\}^m$ , a bit $i=i(n)$ is <strong>hardcore</strong> if for every <strong>p.p.t.</strong> adversary $A$, there is a <strong>negligible</strong> function $\mu$ s.t.</p>

$$
\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x):A(y)=x_i]\le 1/2 +\mu(n)
$$



<p>The definition says that it is <u>hard to guess the $i$-th bit</u> of the inverse given the $y$.</p>
<p>I mentioned above that there are <strong>one-way functions</strong> for which it is easy to compute the first half of the bits of the inverse.</p>
<p>Moreover, there are <strong>functions that are one-way</strong>, yet <u>every bit is somewhat easy to predict</u> with probability $\frac{1}{2}+1/n$.</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> This is actually an (hard) exercise in the lecture.

<p>Sadly, I haven’t figured out the construction that every bit is easy to compute w.p.  $\frac{1}{2}+1/n$.<br>Hope to change the ideas with you.</p>
 </div> </article> 

<p>Although the entire inverse of $f(x)$ is hard to compute, it is indeed possible for $f(x)$ to <u>leak a lot of information</u> about $x$ even if $f$ is <u>one-way.</u></p>
<h2 id="Hardcore-Predicate-Def"><a href="#Hardcore-Predicate-Def" class="headerlink" title="Hardcore Predicate Def"></a>Hardcore Predicate Def</h2><p>So, we <strong>generalize</strong> the notion of <u>a hardcore “bit”.</u></p>
<p>We define <strong>hardcore predicate</strong> to <u>identify a specific piece of information about</u> $x$  that is “hidden” by $f(x)$.</p>
<p>Informally, a <strong>hardcore predicate</strong> of a one-way function $f(x)$ is <u>hard to compute given $f(x)$.</u></p>
 <article class="message is-info"> <div class="message-header"> 

<p><strong>Hardcore Predicate Definition:</strong></p>
 </div> <div class="message-body"> 

<p>For any function (family) $F:\{0,1\}^n\rightarrow \{0,1\}^m$ , a function $B:\{0,1\}^n\rightarrow \{0,1\}$  is a <strong>hardcore predicate</strong> if for every <strong>p.p.t.</strong> adversary $A$, there is a <strong>negligible</strong> function $\mu$ s.t.</p>

$$
\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x):A(y)=B(x)]\le 1/2 +\mu(n)
$$



 </div> </article> 

<p>The definition says that <strong>a hardcore predicate</strong> $B(x)$ <u>of a one-way function</u> $f(x)$ is <strong>hard to compute</strong> with probability non-negligibly better than $1/2$ <strong>given</strong> $f(x)$ since the predicate $B(x)$ is a boolean function that can be computed with probability $1/2$.</p>
<p>Besides, this is perfectly <strong>consistent with the fact</strong> that the <u>entire inverse is actually hard to compute.</u> Otherwise, you can compute $B(x)$.</p>
<hr>
<p>Henceforth, for us, <strong>a hardcore bit will mean a hardcore predicate.</strong></p>
<p>We can represent the definition by the following picture.</p>
<img src="https://s1.ax1x.com/2022/07/23/jXsiEF.png" alt="hard to comput HCB from F" style="zoom:43%;" />

<p>It’s <strong>easy</strong> to compute the one-way function $F(x)$ <strong>given</strong> $x$.</p>
<p>It’s <strong>easy</strong> to compute the hardcore predicate $B(x)$ of $F(x)$  <strong>given</strong> $x$.</p>
<p>But it’s <strong>hard</strong> to compute $B(x)$ <strong>given</strong> $F(x)$.</p>
<p>We know that it is <strong>indeed possible</strong> for $F(x)$ to <u>leak a lot of information about</u> $x$ even if $F$ is one-way.</p>
<p>Hence, the hardcore predicate $B(x)$ <u>represent the specific piece of information about</u> $x$ which is <strong>hard to compute given</strong> $F(x)$.</p>
<h1 id="One-way-Permutations-→-PRG"><a href="#One-way-Permutations-→-PRG" class="headerlink" title="One-way Permutations → PRG"></a>One-way Permutations → PRG</h1><p>In this section, we show that <u>One-way Permutations imply PRG.</u></p>
<p>The construction is as follows:</p>
<p><font color=blue><u><b>PRG Construction from OWP:</b></u></font> </p>
<p>Let $F$ be a one-way permutation, and $B$ an associated hardcore predicate for $F$.</p>
<p>Then, define $G(x)=F(x)||B(x)$.</p>
<p><u>Note</u>: $G$ stretches by one bit. We can turn this into a $G’$ that stretches to any poly. number of bits from <strong>PRG Length Extension.</strong></p>
<p><font color=blue><u><b>Theorem: </b></u></font> </p>
<p>$G$ is a PRG assuming $F$ is a one-way permutation.</p>
<p><font color=blue><u><b>Proof (using NBU): </b></u></font> </p>
<p>The thing <strong>we want to prove</strong> is that if $F$ is a <u>one-way permutation</u> and $B$ is <u>the hardcore predicate for</u> $F$, then $G(x)=F(x)||B(x)$ is a PRG.</p>
<p>We prove it using <strong>next-bit unpredictability.</strong></p>
<ul>
<li><p>Assume for <strong>contradiction</strong> that $G$ is <u>not a PRG.</u></p>
<p>  Therefore, there is <strong>a next-bit predictor</strong> $D$, and index $i$, and a polynomial function $p$ such that</p>
   $\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=G(x):D(y_1\dots y_{i-1})=y_i]\ge \frac{1}{2}+1/p(n)$ 
</li>
<li><p>If we <u>want to get the contradiction to</u> $B(x)$, the <strong>index</strong> $i$ has to be $n+1$.<br>(Because the $G(x)=F(x)||B(x)$ where $F(x)$  is $n$-bit and $B(x)$ is $1$-bit.)</p>
 $\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=G(x):D(y_1\dots y_{n})=y_{n+1}]\ge \frac{1}{2}+1/p(n)$ 
</li>
<li><p>Then we can construct <u>a hardcore bit</u> (predicate) <strong>predictor</strong> from $D$.<br>In fact, $D$ is <strong>a hardcore predictor.</strong></p>
 $\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=G(x):D(F(x))=B(x)]\ge \frac{1}{2}+1/p(n)$ 
</li>
<li><p>QED.</p>
</li>
</ul>
<p><font color=blue><u><b>Proof (using Indistinguishability):</b></u></font> </p>
<p>We can also prove it <u>using indistinguishability.</u></p>
<ul>
<li><p>Assume for <strong>contradiction</strong> that $G$ is not a PRG.<br>Therefore, there is a <strong>p.p.t. distinguisher</strong> $D$, and a <strong>polynomial</strong> function $p$ such that</p>

  $$
  \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=G(x):D(y)=1]  &-  \\ \operatorname{Pr}[y\leftarrow \{0,1\}^{n+1}:D(y)] &\ge  1/p(n)\end{aligned}
  $$
  
</li>
<li><p>We <strong>construct a hardcore predictor</strong> $A$ and show:</p>

  $$
    \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n:A(F(x))=B(x)]\ge \frac{1}{2}+1/p'(n)\end{aligned}
  $$
    
</li>
<li><p>What <strong>information</strong> can we <u>learn from the distinguisher</u> $D$ ?</p>
<ul>
<li><p>Rewrite $y$ in the first term by <u>definition</u>.</p>

      $$
        \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=\color{blue}{F(x)||B(x)}:D(y)=1] &- \\\operatorname{Pr}[y\leftarrow \{0,1\}^{n+1}:D(y)=1]&\ge 1/p(n)\end{aligned}
      $$
        
</li>
<li><p>Rewrite the second term <u>by a syntactic change.</u> </p>

      $$
        \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x)||B(x):D(y)=1]&-\\ \operatorname{Pr}[{\color{blue}{y_0\leftarrow \{0,1\}^{n},y_1\leftarrow \{0,1\}},y=y_0||y_1}:D(y)=1] &\ge 1/p(n)\end{aligned}
      $$
        
</li>
<li><p>Rewire the second term since $F$ is <u>one-way permutation.</u></p>
  

    $$
    \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x)||B(x):D(y)=1]&-\\ \operatorname{Pr}[{\color{blue}{x\leftarrow \{0,1\}^{n},y_1\leftarrow \{0,1\},y=F(x)||y_1}}:D(y)=1] &\ge 1/p(n)\end{aligned}
    $$

    ​		
</li>
<li><p>Rewrite the second term since $\operatorname{Pr}[y_1=0]=\operatorname{Pr}[y_1=0]=1/2$.</p>

      $$
        \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x)||B(x):D(y)=1] &-\\ \frac{\operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||0}}:D(y)=1]+\operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||1}}:D(y)=1]}{2} &\ge 1/p(n)\end{aligned}
      $$
        
</li>
<li><p>Rewrite the second term using $B(x)$.</p>

      $$
        \begin{aligned}\operatorname{Pr}[x\leftarrow \{0,1\}^n;y=F(x)||B(x):D(y)=1] &-\\ \frac{\operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||B(x)}}:D(y)=1]+\operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||\overline{B(x)}}}:D(y)=1]}{2} &\ge 1/p(n)\end{aligned}
      $$
        
</li>
<li><p>Putting thins together.</p>
  
        $$
        \begin{aligned}\frac{1}{2}(\operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||B(x)}}:D(y)=1] &- \\ \operatorname{Pr}[{x\leftarrow \{0,1\}^{n},\color{blue}{y=F(x)||\overline{B(x)}}}:D(y)=1]) &\ge 1/p(n)\end{aligned}
        $$
        

</li>
</ul>
</li>
</ul>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> Although the mathematical transformations seem complex, the main idea is to <u>turn what we know to what we want.</u> 
<p>We want to know some information about $B(x)$. </p>
 </div> </article> 

<ul>
<li>The <strong>takeaway</strong> is that $D$ says 1 more often <u>when fed with the “right bit”</u> than the “wrong bit”.</li>
</ul>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> It’s a familiar statement.

<p>In <a href="/2022/07/06/mit6875-lec3/" title="[Lecture 3]">[Lecture 3]</a> , we construct a predictor from a distinguisher to prove the next-bit unpredictability → the indistinguishability.</p>
<p>In that proof, we got the takeaway from <strong>hybrid argument</strong>, that the distinguisher $D$ says 1 more often when fed with the “right bit” than the “wrong bit”.</p>
 </div> </article> 

<ul>
<li><p>Construct <strong>a hardcore bit predictor</strong> $A$ from the distinguisher $D$ using the takeaway.</p>
<ul>
<li><p>The <strong>task</strong> of $A$ is get as input $z=F(x)$ and try to guess the hardcore predicate.</p>
</li>
<li><p>The predictor works as follows:</p>
  
        $$
        \begin{aligned}A(F(x))=\begin{cases} b,& \text{if }D(F(x)||b)=1\\ \overline{b},& \text{otherwise}\end{cases},b\leftarrow\{0,1\} \end{aligned}
        $$

        

<ol>
<li>Pick a random bit $b$.</li>
<li>Feed $D$ with input $z||b$</li>
<li>If $D$ says “1”, output $b$ as the prediction for the hardcore bit and if $D$ says “0”, output $\overline{b}$.</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>Analysis</strong> of the predictor $A$.</p>
<ul>
<li>$\operatorname{Pr}[x\leftarrow {0,1}^n:A(F(x))=B(x)]$</li>
<li>$A$ output $b=B(x)$ or $\overline{b}=B(x)$. $\begin{aligned} =\operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||b)=1 \color{blue}{\wedge b=B(x)}] + \\ \operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||b)=0 \color{blue}{\wedge b\ne B(x)}]& \\\end{aligned}$ 
      $\begin{aligned}=\operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||b)=1 \mid b=B(x)]\operatorname{Pr}[b=B(x)]& + \\ \operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||b)=0 \mid b\ne B(x)]\operatorname{Pr}[b\ne B(x)]& \end{aligned}$ </li>
<li>Since $b$ is random.<br>$\begin{aligned}=\color{blue}{\frac{1}{2}}(\operatorname{Pr}[x\leftarrow{0,1}^n:D(F(x)||b)=1 \mid b=B(x)]&amp; + \ \operatorname{Pr}[x\leftarrow{0,1}^n:D(F(x)||b)=0 \mid b\ne B(x)]&amp;) \end{aligned}$</li>
<li>Put the prior condition in it.$\begin{aligned}=\frac{1}{2}(\operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||\color{blue}{B(x)})=1]& + \\ \operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||\color{blue}{\overline{B(x)}})=0 ) \end{aligned}$
      $\begin{aligned}=\frac{1}{2}(\operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||\color{blue}{B(x)})=1]& + \\ 1-\operatorname{Pr}[x\leftarrow\{0,1\}^n:D(F(x)||\color{blue}{\overline{B(x)}})=1 ) \end{aligned}$ </li>
<li>From the takeaway, we can get<br>$=\frac{1}{2}(1+(*))\ge \frac{1}{2} + 1/p(n)$</li>
<li>So the $A$ <u>can predict the hardcore bit</u> (predicate) with probability non-negligible better than $1/2$.</li>
</ul>
</li>
</ul>
<h1 id="Goldreich-Levin-Theorem-every-OWF-has-a-HCB"><a href="#Goldreich-Levin-Theorem-every-OWF-has-a-HCB" class="headerlink" title="Goldreich-Levin Theorem: every OWF has a HCB."></a>Goldreich-Levin Theorem: every OWF has a HCB.</h1><h2 id="A-Universal-Hardcore-Predicate-for-all-OWF"><a href="#A-Universal-Hardcore-Predicate-for-all-OWF" class="headerlink" title="A Universal Hardcore Predicate for all OWF"></a>A Universal Hardcore Predicate for all OWF</h2><p>We have defined the hardcore predicate $B(x)$ for the particular one-way function $F(x)$.</p>
<p>Let’s shoot for a <strong>universal</strong> hardcore predicate <u>for every one-way function</u>, i.e., a <strong>single</strong> predicate $B$ where it is hard to guess $B(x)$ given $F(x)$.</p>
<p>Is this possible ? </p>
<p>Turns out the answer is <strong>“no”.</strong></p>
<p>Pick a favorite amazing $B$. We can <u>construct a one-way function</u> $F$ which $B$ is <strong>not</strong> hardcore.</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>There is a <strong>contradiction</strong> example. 
<p><u>Claim 1</u>: If $f(x)$ is a one-way function, then $f’(x)=f(x)||B(x)$ is one-way as well.<br><u>Claim 2</u>:<br>But $B(x)$ is <strong>NOT</strong> a hardcore predicate for $f’(x)$.</p>
<p>For claim 1, if you can compute the inverse of $f’(x)$, then you can compute the inverse of $f(x)$.<br>For claim 2, $B(x)$ is actually written in $f’(x)$.<br>So $f’(x)$ is one-way and dose not leak much information.</p>
 </div> </article> 

<h2 id="Goldreich-Levin-GL-Theorem"><a href="#Goldreich-Levin-GL-Theorem" class="headerlink" title="Goldreich-Levin(GL) Theorem"></a>Goldreich-Levin(GL) Theorem</h2><p>But Goldreich-Levin(GL) Theorem changes the statement to <strong>a random hardcore</strong> and tells us <strong>every one-way function has a hardcore predicate/bit.</strong></p>
 <article class="message is-info"> <div class="message-header"> 

<p><strong>Goldreich-Levin(GL) Theorem:</strong> </p>
 </div> <div class="message-body"> 

<p>Let $\{B_r:\{0,1\}^n\rightarrow \{0,1\}\}$ where</p>

$$
B_r(x)=\langle r, x \rangle =\sum_{i=1}^n r_ix_i \mod 2
$$



<p>be a <strong>collection</strong> of predicates (one for each $r$). </p>
<p>Then a <font color="red">random</font> $B_r$ is hardcore for <font color="red">every</font> one-way function $F$.</p>
<p>That is, for every one-way function $F$, every p.p.t. $A$, there is a negligible function $\mu$ s.t.</p>

$$
\operatorname{Pr}[x\leftarrow \{0,1\}^n;r\leftarrow \{0,1\}^n:A(F(x),r)=B_r(x)]\le\frac{1}{2} +\mu(n)
$$



 </div> </article> 

<p>It defines <u>a collection of predicates</u> ${B_r:{0,1}^n\rightarrow {0,1}}$ <strong>indexed</strong> by $r$, a $n$-bit vector. So the evaluation of $B_r(x)$ is essentially an <u>inner product</u> of $r$ and $x$ (mod 2).</p>
<p>The definition says that a <strong>random</strong> $B_r$ is hardcore <strong>for every one-way funciton</strong> $F$.</p>
<p>So it picks a random $x$ and a <strong>random</strong> $r$.</p>
<p>For every p.p.t. adversary $A$, it is <strong>hard to compute</strong> $B_r(x)$ given $F(x)$ and $r$.</p>
<h2 id="Alternative-Interpretations-to-GL-Theorem"><a href="#Alternative-Interpretations-to-GL-Theorem" class="headerlink" title="Alternative Interpretations to GL Theorem"></a>Alternative Interpretations to GL Theorem</h2><p>There are some alternative interpretations to GL Theorem.</p>
<p><font color=blue><u><b>Alternative Interpretation 1: </b></u></font> </p>
<p>For every one-way function $F$, there is a <strong>related</strong> one-way function $F’(x,r)=(F(x),r)$ which has a <strong>deterministic</strong> hardcore predicate.</p>
<hr>
<p>For every one-way function $F$, you can change it to <u>a related one-way function</u> $F’(x,r)=(F(x),r)$. Although $F’$ leak the second half of bits, $F’$  is one-way.</p>
<p>Then $F’$has a <strong>deterministic</strong> hardcore predicate $B(x,r)=\langle x,r \rangle\pmod 2$.</p>
<p>$B(x,r)$ is a <u>fixed function</u>, which performs an inner-product mod 2 between the first half and the second half of the inputs.</p>
<p>Hence, in this interpretation, GL Theorem says that $B$ is not a hardcore bit for every OWF, but it’s <u>a hardcore bit for the related function</u>, which we created it from the OWF.</p>
<p>Moreover, if $F(x)$ is one-way permutation, then $F’(x,r)=(F(x),r)$ is one-way permutation.</p>
<p>And we can get a PRG from $F’(x,r)$. Then $G(x,r)=F(x)||r||\langle x,r\rangle$  where the last bit is the hardcore bit.</p>
<p><font color=blue><u><b>Alternative Interpretation 2: </b></u></font> </p>
<p>For every one-way function $F$, there exists (non-uniformly) a (possibly different) hardcore predicate $\langle r_F,x\rangle$.</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> To be honest, I do not comprehend the advanced statement.

<p>The professor left a cool open problem: remove the non-uniformity.</p>
 </div> </article> 

<h2 id="Proof-of-GL-Theorem"><a href="#Proof-of-GL-Theorem" class="headerlink" title="Proof of GL Theorem"></a>Proof of GL Theorem</h2><p>Assume for <strong>contradiction</strong> there is a <u>predictor</u> $P$ and a polynomial $p$ s.t.</p>
<p>$\operatorname{Pr}[x\leftarrow {0,1}^n;r\leftarrow {0,1}^n:P(F(x),r)=\langle r,x\rangle]\ge\frac{1}{2} +p(n)$</p>
<p>We need to show an <u>inverter</u> $A$ for $F$ and a polynomial $p’$  such that</p>
<p>$\operatorname{Pr}[x\leftarrow {0,1}^n:A(F(x))=x’:F(x’)=F(x)]\ge 1/p’(n)$</p>
<p>But it is too hard to prove this contradiction.</p>
<p>Let’s make our lives easier.</p>
<h3 id="A-Perfect-Predicator"><a href="#A-Perfect-Predicator" class="headerlink" title="A Perfect Predicator"></a>A Perfect Predicator</h3><p>For simplicity, we assume a perfect predicator.</p>
<p><font color=blue><u><b>Assume a perfect predictor: </b></u></font> </p>
<ul>
<li><p>Assume a <strong>perfect predictor</strong> $P$, which <u>can completely predicte the HCB correctly</u>, s.t.</p>

  
    $\operatorname{Pr}[x\leftarrow \{0,1\}^n;r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]=1$ 
</li>
<li><p>Now we can <strong>construct an inverter</strong> $A$ for $F$.</p>
<p>  The inverter $A$ works as follows:</p>
<p>  On input $y=F(x)$, $A$ runs the predictor $P$ $n$ times on input $(y, e_1),(y,e_2),\dots,$and $(y,e_n)$ where $e_1=100..0,e_2=010..0,\dots$ are the <u>unit vectors.</u></p>
</li>
<li><p>Since $A$ is perfect, it returns $\langle e_i,x\rangle=x_i$, <u>the $i$-th bit</u> of $x$ on the $i$-th invocation.</p>
</li>
</ul>
<h3 id="A-Pretty-Good-Predictor"><a href="#A-Pretty-Good-Predictor" class="headerlink" title="A Pretty Good Predictor"></a>A Pretty Good Predictor</h3><p>Then we assume less.</p>
<p><font color=blue><u><b>Assume a pretty good predictor:</b></u></font> </p>
<ul>
<li>Assume a <strong>pretty good predictor</strong> $P$, s.t. $\operatorname{Pr}[x\leftarrow \{0,1\}^n;r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{3}{4} + 1/p(n)$ </li>
<li>What can we learn from the predictor ?</li>
</ul>
<p><font color=blue><u><b><i>Claim: </i></b></u></font><br>For <strong>at least a $1/2p(n)$ fraction</strong> of the $x$,<br>$\operatorname{Pr}[r\leftarrow {0,1}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{3}{4} + 1/2p(n)$</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i><strong>How to derive the claim by averaging argument ?</strong>  
<p>When I wrote this blog, I contemplated it for a long long time.<br>I figured it out with the help of <strong>Wengjie Li</strong>. Thanks!<br>I read the details about the proof of GL Theorem in some textbooks.<br>Some proved <u>the lower bound of fraction</u> $1/2p(n)$, but <u>how about the lower bound of probability</u>, $\frac{3}{4}+1/2p(n)$?<br>In fact, they are related.</p>
 </div> </article> 

<p>Before that, let’s introduce <u>averaging argument.</u></p>
<blockquote>
<p>In computational complexity theory and cryptography, <strong>averaging argument</strong> is a <u>standard argument for proving theorems.</u> It usually allows us to <u>convert probabilistic polynomial-time algorithms into non-uniform polynomial-size circuits.</u><br>——Wiki</p>
</blockquote>
 <article class="message is-info"> <div class="message-header"> 

<p><strong>Averaging Argument:</strong></p>
 </div> <div class="message-body"> 

<p>Let $f$ be some function. The averaging argument is the following claim:</p>
<p>If we have a circuit $C$ such that $C(x,y)=f(x)$ <u>with probability at least</u> $\rho$ where $x$ is <u>chosen at random</u> and $y$ is <u>chosen independently</u> from some distribution $Y$ over $\{0,1\}^m$ (which might not even be effciently sampleable),</p>
<p>then there <strong>exists a single string</strong>  $y_0\in \{0,1\}^m$  such that $\operatorname{Pr}_x[C(x,y_0)=f(x)]\ge \rho$. </p>
<hr>
<p>Indeed, for every $y$ define $p_y$ to be $\operatorname{Pr}_x[C(x,y)=f(x)]$, then</p>

$$
\operatorname{Pr}_{x,y}[C(x,y)=f(x)]=\mathbb{E}_y[p_y]
$$



<p>and then this reduces to the <strong>claim</strong> that for <u>every random variable</u> $Z$, if $\mathbb{E}[Z]\ge \rho$ then $\operatorname{Pr}[Z\ge \rho]&gt;0$ <em>(this holds since $\mathbb{E}[Z]$ is the weighted average of Z and clearly if the average of some values is at least $\rho$ then one of the values must be at least $\rho$.)</em> </p>
 </div> </article> 

<p>The <strong>claim</strong> tells us if $\operatorname{Pr}_{x,y}[C(x,y)=f(x)]\ge \rho$, then <u>there exist some</u> $y_0$ <strong>such that</strong> $\operatorname{Pr}_x[C(x,y_0)=f(x)]\ge \rho$ as well. </p>
<p>So we can <strong>single out</strong> these $y_0$ <u>using averaging argument.</u></p>
<p>Actually, I think the equation, $\operatorname{Pr}_{x,y}[C(x,y)=f(x)]=\mathbb{E}_y[p_y]$, is the <u>manifestation of averaging.</u></p>
<article class="message message-immersive is-warning">  <div class="message-body">  <i class="fas fa-exclamation-triangle mr-2"></i> The following analysis is mostly my <strong>own deduction and comprehension</strong> since the proof is omitted in the lecture.  <br> <strong>Corrections and advice are welcome.</strong>  </div>  </article>

<p><font color=blue><u><b><i>Some analysis to $\operatorname{Pr}_{x,y}[C(x,y)=f(x)]=\mathbb{E}_y[p_y]$: </i></b></u></font> </p>
<ul>
<li>By definition of $p_y$<ul>
<li>$y$ is a variable and $p_y$ is a variable.</li>
<li>By definition, $p_y$ <strong>is up to</strong> $y$.</li>
<li>So the <u>distribution of $p_y$ is equal to the distribution of  $y$.</u></li>
</ul>
</li>
<li>Expand the left term.<br>$\operatorname{Pr}_{x,y}[C(x,y)=f(x)]=\sum _i \operatorname{Pr}_x[C(x,y_i)=f(x)]\operatorname{Pr}[y=y_i]$</li>
<li>The right term is the <strong>expected value</strong> of variable $p_y$. <ul>
<li> $\mathbb{E}_y[p_y] = \sum_i p_{y_i} \cdot \operatorname{Pr}[p_y=p_{y_i}]$ </li>
<li>Because the distribution of $p_y$ is equal to the distribution of  $y$.<br>$\operatorname{Pr}[p_y=p_{y_0}]=\operatorname{Pr}[y={y_0}]$</li>
<li>So, $\mathbb{E}_y[p_y] = \sum_i p_{y_i} \cdot \operatorname{Pr}[y=y_i]$ </li>
<li>= the left term.</li>
</ul>
</li>
</ul>
<hr>
<p>Now back to the claim.</p>
<article class="message message-immersive is-warning">  <div class="message-body">  <i class="fas fa-exclamation-triangle mr-2"></i> The following is mostly my <strong>own deduction and comprehension</strong> since the proof is omitted in the lecture.  <br> <strong>Corrections and advice are welcome.</strong>  </div>  </article>

<p><font color=blue><u><b><i>Proof of the Claim : </i></b></u></font> </p>
<p><font color=blue><u><b><i>What can we learn from the claim? </i></b></u></font> </p>
<ul>
<li>What do we <strong>know from the predictor</strong> ?<ul>
<li>We know $\operatorname{Pr}_{x,r}[P(F(x),r)=\langle r,x\rangle]\ge \frac{3}{4} + 1/p(n)$.</li>
<li><u>For every</u> $x$, define $p_x=\operatorname{Pr}_r[P(F(x),r)=\langle r,x\rangle]$.</li>
<li>By <strong>averaging argument,</strong><ol>
<li>We know <u>there exists some</u> $x$ such that $p_x\ge \frac{3}{4} + 1/p(n)$.</li>
<li>We know $\operatorname{Pr}_{x,r}[P(F(x),r)=\langle r,x\rangle]=\mathbb{E}[p_x]$ by averaging argument.</li>
<li>So we know <u>the lower bound of</u>  $\mathbb{E}[p_x]$ (<strong>expected</strong> value of $p_x$) is $\frac{3}{4} + 1/p(n)$.</li>
</ol>
</li>
</ul>
</li>
<li>What do we <strong>really want</strong> ?<ul>
<li>We want to <u>single out these</u> $x$ such that $p_x$ is <u>non-negligibly better than</u> $\frac{3}{4}$ <strong>in (probabilistic) polynomial time.</strong></li>
<li>So we <strong>want a set of $x$</strong>, which <u>the fraction is polynomial</u> , for every $x$ in the set, the $p_x$ is <u>non-negligibly better than</u> $\frac{3}{4}$.</li>
</ul>
</li>
<li>We show <strong>the fraction and the (lower bound of ) probability are related.</strong></li>
<li><u>Notation</u><ul>
<li>$\epsilon$ define <u>the lower bound</u> of $\mathbb{E}[p_x]$, i.e. $\epsilon =\frac{3}{4} + 1/p(n)$.</li>
<li>Define a <strong>good set of $x$</strong> as $S$ and $s$ <strong>denotes</strong> <u>the poly. fraction of the</u> $x$. ($|S|=s\cdot 2^n$). $S=\{x\mid p_x \ge \varepsilon' \}$  <br>where $\varepsilon’$ <strong>denotes</strong> the <u>lower bound of $p_x$ for every $x\in S$,</u>  non-negligibly better than $\frac{3}{4}$.</li>
</ul>
</li>
<li>Rewrite $\mathbb{E}[p_x]$ using $s$ and $\varepsilon$.<ul>
<li>$p_x=
    \begin{cases}
     \varepsilon' \le p_x\le 1,& x\in S \\ 
    0\le  p_x \le \varepsilon',& x\notin S
    \end{cases}$ </li>
<li>Similarly, $p_x$ <strong>is up to</strong> $x$.<br>Hence, <u>the distribution of $p_x$ is equal to the distribution of $x$,</u> i.e.$\operatorname{Pr}[p_x]=\operatorname{Pr}[x]$</li>
<li>$\mathbb{E}[p_x] = \sum p_x \cdot \operatorname{Pr}[p_x]=\sum p_x \cdot \operatorname{Pr}[x]$<ul>
<li>$=\sum p_x \cdot \operatorname{Pr}[x\in S] + \sum p_x \cdot \operatorname{Pr}[x\notin S]$</li>
<li>$=\sum p_x \cdot s + \sum p_x \cdot (1-s)$</li>
</ul>
</li>
<li>We do not know the actual $p_x$ but we <strong>know the boundary</strong> of $p_x$.</li>
</ul>
</li>
<li>Calculate the boundary of $\mathbb{E}[p_x]$ using $s$ and $\varepsilon$.<ul>
<li>$\mathbb{E}[p_x] =\sum p_x \cdot s + \sum p_x \cdot (1-s)$</li>
<li>The lower bound is $\varepsilon’ \cdot s + 0\cdot (1-s)=\varepsilon’ \cdot s$ (useless)</li>
<li>The <u>upper bound</u> is $1\cdot s + \varepsilon’ \cdot (1-s)=s+\varepsilon’ (1-s)$  (<strong>useful</strong>)</li>
</ul>
  <strong>This upper bound should be greater than the known lower bound $\epsilon$.</strong></li>
<li>We get the relation of $s$ and $\varepsilon’$.<ul>
<li>$\epsilon \le s+\varepsilon’ (1-s)$</li>
<li>$\frac{\epsilon-s}{1-s}\le \varepsilon’$  (since $s&lt;1$)</li>
</ul>
</li>
<li>Take $\epsilon$   with $\frac{3}{4} + 1/p(n)$.<ul>
<li>We want the fraction $s$ to <u>be polynomial.</u></li>
<li>Suppose the fraction $s=1/2p(n)$.<br>We can get $\varepsilon’ \ge \epsilon -s = \frac{3}{4} +1/2p(n)$. (since $1-s$ is very small).</li>
<li>We can also suppose the fraction $s=1/3p(n)$ and so on.</li>
<li>The <strong>point I want to elucidate</strong> here is the <strong>fraction</strong> $s$ and the <strong>lower bound</strong> of $p_x$ for every $x\in S$ <u>can both be polynomial</u> if <u>the advantage of predicting is non-negligible</u>.</li>
</ul>
</li>
<li>Hence, <font color="red"> the <strong>takeaway</strong> is if <u>the probability of predicting  is non-negligibly</u> better than $3/4$, then we <strong>can single out these “good $x$ ”</strong>in  (probabilistic) polynomial time.</font> </li>
<li>Similarly, <font color="red">if the probability of predicting  is <u>non-negligibly better than</u> $1/2$ (the predictor in general case), we <strong>can also single out these “good</strong> $x$ ” in (probabilistic) polynomial time.</font> </li>
</ul>
<hr>
<p>We get the <strong>takeaway</strong> that if the probability of predicting  is <u>non-negligibly</u> better than $3/4$, then we <u>can single out</u> these “good $x$ ” in (probabilistic) polynomial time.</p>
<p><font color=blue><u><b><i>Invert the i-th bit: </i></b></u></font> </p>
<ul>
<li><p>Now we <strong>can compute the $i$-th bit</strong> of $x$ with the probability better than $1/2$.<br>The key idea is <strong>linearity</strong>.</p>
<ol>
<li>Pick a random $r$</li>
<li>Ask $P$ to tell us $\langle r,x\rangle$ and $\langle r+e_i,x \rangle$.</li>
<li>Subtract the two answers to get $\langle e_i,x\rangle =x_i$</li>
</ol>
</li>
<li><p><strong>Proof of invert $i$-th bit:</strong></p>
<ul>
<li><p>$\operatorname{Pr}[\text{we compute }x_i \text{ correctly}]$</p>
</li>
<li><p>$\ge \operatorname{Pr}[P \text{ predicts }\langle r,x \rangle \text{ and }\langle r+e_i,x \rangle \text{ correctly}]$</p>
</li>
<li><p>$=1-\operatorname{Pr}[P \text{ predicts }\langle r,x \rangle \text{ or }\langle r+e_i,x \rangle \text{ wrong}]$</p>
</li>
<li><p>$\ge1-\operatorname{Pr}[P \text{ predicts }\langle r,x \rangle  \text{ wrong}]\text{ + } \operatorname{Pr}[P \text{ predicts }\langle r+e_i,x \rangle \text{ wrong}]$<br>(by <strong>union bound</strong>)</p>
</li>
<li><p>$\ge 1 - 2\cdot (\frac{1}{4} -\frac{1}{2p(n)})=\frac{1}{2}+1/p(n)$</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i> I think it takes the fraction as $1/2p(n)$ just to make the advantage equal to $1/p(n)$. It’s beautiful. </div> </article> 

</li>
</ul>
</li>
</ul>
<p><font color=blue><u><b><i>Invert the entire x: </i></b></u></font> </p>
<ul>
<li>Construct the Inverter $A$<ul>
<li>Repeat for each bit $i\in{1,2,\dots, n}$:<ul>
<li>Repeat $p(n) \cdot p(n)$ times:<br>(one $p(n)$ is for <u>singling out</u>, and another is <u>for computing correctly</u>)<ol>
<li>Pick a random $r$</li>
<li>Ask $P$ to tell us $\langle r,x\rangle$ and $\langle r+e_i,x \rangle$.</li>
<li>Subtract the two answers to get $\langle e_i,x\rangle =x_i$</li>
</ol>
</li>
<li>Compute the <strong>majority</strong> of all such guesses and set the bit as $x_i$.</li>
</ul>
</li>
<li>Output the concatenation of all $x_i$ as $x$.</li>
</ul>
</li>
<li>Analysis of $A$ is ommited.<br>Hint: Chernoff + Union Bound.</li>
</ul>
<h3 id="A-General-Predictor"><a href="#A-General-Predictor" class="headerlink" title="A General Predictor"></a>A General Predictor</h3><p>Let’s proceed to a general predictor, which is in the foremost contradiction.</p>
<p><font color=blue><u><b>Assume a general good predictor:</b></u></font> </p>
<p>Assume there is a predictor $P$ and a polynomial $p$ s.t.</p>


$\operatorname{Pr}[x\leftarrow \{0,1\}^n;r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]\ge\frac{1}{2} +p(n)$



<p>Likewise, there is a similar claim.</p>
<p><font color=blue><u><b><i>Claim: </i></b></u></font> </p>
<p>For <strong>at least a $1/2p(n)$ fraction</strong> of the $x$,</p>
 $\operatorname{Pr}[r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{1}{2} + 1/2p(n)$ 

<p>The <strong>takeaway</strong> is that <u>probability of predicting  is non-negligibly better than</u> $1/2$ , we <u>can single out these “good</u> $x$ ” in (probabilistic) polynomial time.</p>
<p>However, we <strong>cannot</strong> invert the $i$-th bit of $x$ with the probability better than $1/2$ using the above method.</p>
<p><font color=blue><u><b><i>Analysis of Inverting $x_i$: </i></b></u>(error doubling)</font> </p>
<p>(For at least $1/2p(n)$ fraction of the $x$)</p>
<ul>
<li><p>If the probability of predicting  $\langle r,x\rangle$  correctly is non-negligibly <strong>better than</strong> $3/4 + 1/2p(n)$, i.e.</p>
 $\operatorname{Pr}[r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{3}{4} + 1/2p(n)$ 

<ul>
<li><p>$\operatorname{Pr}[\text{we compute }x_i \text{ correctly}]$</p>
</li>
<li><p>$\ge \operatorname{Pr}[P \text{ predicts }\langle r,x \rangle \text{ and }\langle r+e_i,x \rangle \text{ correctly}]$</p>
</li>
<li><p>$=1-\operatorname{Pr}[P \text{ predicts }\langle r,x \rangle \text{ or }\langle r+e_i,x \rangle \text{ wrong}]$</p>
</li>
<li><p>$\ge1-\operatorname{Pr}[P \text{ predicts }\langle r,x \rangle  \text{ wrong}]\text{ + } \operatorname{Pr}[P \text{ predicts }\langle r+e_i,x \rangle \text{ wrong}]$</p>
</li>
<li><p>$\ge 1 -  \color {blue}{2\cdot(\frac{1}{4} -\frac{1}{2p(n)})}=\frac{1}{2}+1/p(n)$</p>
<p>So it <strong>can compute</strong> $x_i$ with advantage $1/p(n)$.</p>
</li>
</ul>
</li>
<li><p>If the probability of predicting  $\langle r,x\rangle$  correctly is <strong>exactly</strong> $3/4$, i.e.</p>
$\operatorname{Pr}[r\leftarrow \{0,1\}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{3}{4}$ 

<ul>
<li><p>$\operatorname{Pr}[\text{we compute }x_i \text{ correctly}]$</p>
</li>
<li><p>$\ge 1 - \color{blue} {2\cdot(\frac{1}{4})}=1/2$ </p>
<p>It is <strong>unlikely</strong> to compute $x_i$ since it’s the same with random. </p>
</li>
</ul>
</li>
<li><p>If the probability of predicting  $\langle r,x\rangle$  correctly is non-negligibly <strong>better than</strong> $1/2 + 1/2p(n)$, i.e.<br>$\operatorname{Pr}[r\leftarrow {0,1}^n:P(F(x),r)=\langle r,x\rangle]\ge \frac{1}{2} + 1/2p(n)$</p>
<ul>
<li><p>$\operatorname{Pr}[\text{we compute }x_i \text{ correctly}]$</p>
</li>
<li><p>$\ge 1 - \color{blue} {2\cdot(\frac{1}{2} -\frac{1}{2p(n)})}=1/p(n)$</p>
<p>It cannot <strong>compute</strong> $x_i$.</p>
</li>
</ul>
</li>
</ul>
<hr>
<p>The problem above is that it <strong>doubles</strong> <u>the original error probability of predicting</u>,  i.e. $1-2\cdot(*)$.</p>
<p>When the probability of error is <strong>significantly smaller than</strong> $1/4$, the “error-doubling” phenomenon raises <u>no problem.</u></p>
<p>However, <strong>in general case</strong> (and even in special case where the error probability is <strong>exactly</strong> $1/4$), the procedure <u>is unlikely to compute</u> $x_i$.</p>
<p>Hence, <strong>what is required</strong> is an alternative way of using the predictor $P$, which <strong>dose not</strong> double the original error probability of $P$.</p>
<p>The complete proof is referred in <a target="_blank" rel="noopener" href="http://www.wisdom.weizmann.ac.il/~oded/PSBookFrag/part2N.ps">Goldreich Book Part 1, Section 2.5.2.</a></p>
<p>The <strong>key idea</strong> is <u>pairwise independence.</u></p>
<article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>
I read the reference. To be honest, I do not comprehend it thoroughly.<br>
Happy to exchange the ideas.</div> </article>

<h2 id="The-Coding-Theoretic-View-of-GL"><a href="#The-Coding-Theoretic-View-of-GL" class="headerlink" title="The Coding-Theoretic View of GL"></a>The Coding-Theoretic View of GL</h2><article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>To be honest, I just write it down so I could figure it out in the near future.<br>
Happy to exchange the ideas.</div> </article>

<ul>
<li><p>$x\rightarrow (\langle x,r\rangle )_{r\in{0,1}^n}$ can be viewed as a highly redundant, exponentially long encoding of $x$ = <strong>the Hadamard code.</strong></p>
</li>
<li><p>$P(F(x),r)$ can be thought of as providing access to a <strong>noisy</strong> codeword.</p>
</li>
<li><p>What we proved = <strong>unique decoding</strong> algorithm for Hadamard code with error rate $\frac{1}{4}-1/p(n)$.</p>
</li>
<li><p>The real proof = <strong>list-decoding</strong> algorithm for Hadamard code with error rate rate $\frac{1}{2}-1/p(n)$.</p>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>「Cryptography-MIT6875」: Lecture 7</p><p><a href="https://f7ed.com/2022/07/20/mit6875-lec7/">https://f7ed.com/2022/07/20/mit6875-lec7/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>f7ed</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2022-07-20</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-08-12</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="icons" rel="noopener" target="_blank" title="Share Alike" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-sa"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/OWF/">OWF, </a><a class="link-muted" rel="tag" href="/tags/OWP/">OWP, </a><a class="link-muted" rel="tag" href="/tags/HCB/">HCB, </a><a class="link-muted" rel="tag" href="/tags/GL-Theorem/">GL Theorem </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/qrcode_wechat.jpg" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/f7ed" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/qrcode_alipay.jpg" alt="Alipay"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/07/23/mit6875-lec8/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">「Cryptography-MIT6875」: Lecture 8</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/07/14/mit6875-lec6/"><span class="level-item">「Cryptography-MIT6875」: Lecture 6 - Number Theory</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "29b443cd5f31ea20197eb10259662cfc",
            repo: "f7ed.github.io",
            owner: "f7ed",
            clientID: "ec59f5258ac0ec443907",
            clientSecret: "f092b308c3e1b46327481c3547ee0dd7fc1bda10",
            admin: ["f7ed"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "en",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/profile.png" alt="f7ed"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">f7ed</p><p class="is-size-6 is-block">热爱可抵漫长岁月。</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">71</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">139</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="mailto:f7edliu@outlook.com" target="_blank" rel="noopener">Email me</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/f7ed"><i class="fab fa-github"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#One-way-Functions"><span class="level-left"><span class="level-item">1</span><span class="level-item">One-way Functions</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Definition"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Definition</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Hardcore-Bits"><span class="level-left"><span class="level-item">2</span><span class="level-item">Hardcore Bits</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Hardcore-Bit-Def"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Hardcore Bit Def</span></span></a></li><li><a class="level is-mobile" href="#Hardcore-Predicate-Def"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Hardcore Predicate Def</span></span></a></li></ul></li><li><a class="level is-mobile" href="#One-way-Permutations-→-PRG"><span class="level-left"><span class="level-item">3</span><span class="level-item">One-way Permutations → PRG</span></span></a></li><li><a class="level is-mobile" href="#Goldreich-Levin-Theorem-every-OWF-has-a-HCB"><span class="level-left"><span class="level-item">4</span><span class="level-item">Goldreich-Levin Theorem: every OWF has a HCB.</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#A-Universal-Hardcore-Predicate-for-all-OWF"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">A Universal Hardcore Predicate for all OWF</span></span></a></li><li><a class="level is-mobile" href="#Goldreich-Levin-GL-Theorem"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Goldreich-Levin(GL) Theorem</span></span></a></li><li><a class="level is-mobile" href="#Alternative-Interpretations-to-GL-Theorem"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Alternative Interpretations to GL Theorem</span></span></a></li><li><a class="level is-mobile" href="#Proof-of-GL-Theorem"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">Proof of GL Theorem</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#A-Perfect-Predicator"><span class="level-left"><span class="level-item">4.4.1</span><span class="level-item">A Perfect Predicator</span></span></a></li><li><a class="level is-mobile" href="#A-Pretty-Good-Predictor"><span class="level-left"><span class="level-item">4.4.2</span><span class="level-item">A Pretty Good Predictor</span></span></a></li><li><a class="level is-mobile" href="#A-General-Predictor"><span class="level-left"><span class="level-item">4.4.3</span><span class="level-item">A General Predictor</span></span></a></li></ul></li><li><a class="level is-mobile" href="#The-Coding-Theoretic-View-of-GL"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">The Coding-Theoretic View of GL</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/f1ed_logo.png" alt="fred&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 f7ed</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent " target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="f7ed&#039;s GitHub" href="https://github.com/f7ed"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script>
      var sc_project=12961083;
      var sc_invisible=1;
      var sc_security="ad3fb575";
      var sc_https=1;
      var sc_remove_link=1;</script><script src="https://www.statcounter.com/counter/counter.js" async></script><noscript><div class="statcounter"><img class="statcounter" src="https://c.statcounter.com/12961083/0/ad3fb575/1/" alt="real time web analytics"></div></noscript><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>