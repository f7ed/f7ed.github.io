<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>「Algebraic ECCs」: Lec3 GV Bound and q-ARY Entropy - fred&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="fred&#039;s blog"><meta name="msapplication-TileImage" content="/img/heart.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="fred&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="In this series, I will be learning Algebraic Error Correcting Codes, lectured by Mary Wootters. The lecture videos are available here. Feedback and sugguestions are always welcome! ^ - ^    Top"><meta property="og:type" content="blog"><meta property="og:title" content="「Algebraic ECCs」: Lec3 GV Bound and q-ARY Entropy"><meta property="og:url" content="https://f7ed.com/2024/12/25/stanford-cs250-ecc-lec3/"><meta property="og:site_name" content="fred&#039;s blog"><meta property="og:description" content="In this series, I will be learning Algebraic Error Correcting Codes, lectured by Mary Wootters. The lecture videos are available here. Feedback and sugguestions are always welcome! ^ - ^    Top"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://f7ed.com/gallery/thumbnails/stanford-cs250-ecc-lec3-thumbnail.png"><meta property="article:published_time" content="2024-12-25T16:00:00.000Z"><meta property="article:modified_time" content="2024-12-26T06:54:08.680Z"><meta property="article:author" content="f7ed"><meta property="article:tag" content="Cryptography"><meta property="article:tag" content="ECC"><meta property="article:tag" content="GV Bound"><meta property="article:tag" content="q-ary Entropy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/thumbnails/stanford-cs250-ecc-lec3-thumbnail.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://f7ed.com/2024/12/25/stanford-cs250-ecc-lec3/"},"headline":"「Algebraic ECCs」: Lec3 GV Bound and q-ARY Entropy","image":["https://f7ed.com/gallery/thumbnails/stanford-cs250-ecc-lec3-thumbnail.png"],"datePublished":"2024-12-25T16:00:00.000Z","dateModified":"2024-12-26T06:54:08.680Z","author":{"@type":"Person","name":"f7ed"},"publisher":{"@type":"Organization","name":"fred's blog","logo":{"@type":"ImageObject","url":"https://f7ed.com/img/f1ed_logo.png"}},"description":"In this series, I will be learning Algebraic Error Correcting Codes, lectured by Mary Wootters. The lecture videos are available here. Feedback and sugguestions are always welcome! ^ - ^    Top"}</script><link rel="canonical" href="https://f7ed.com/2024/12/25/stanford-cs250-ecc-lec3/"><link rel="icon" href="/img/heart.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-M5KG3CQTSF" async></script><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-M5KG3CQTSF');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="fred's blog" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/f1ed_logo.png" alt="fred&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/liu">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/f7ed"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-bars"></i>「Algebraic ECCs」: Lec3 GV Bound and q-ARY Entropy</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-12-25T16:00:00.000Z" title="2024-12-25T16:00:00.000Z">2024-12-26</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-12-26T06:54:08.680Z" title="2024-12-26T06:54:08.680Z">2024-12-26</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Cryptography-ECCs/">Cryptography-ECCs</a></span><span class="level-item"><i class="far fa-clock"></i> 26 minutes read (About 3856 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><article class="message message-immersive is-info">
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="message-body">
<i class="fas fa-info-circle mr-2"></i>
    In this <a href="/categories/Cryptography-ECCs">series</a>, I will be learning <strong>Algebraic Error Correcting Codes</strong>, lectured by Mary Wootters. The lecture videos are available <a target="_blank" rel="noopener" href="https://youtube.com/playlist?list=PLkvhuSoxwjI_UudECvFYArvG0cLbFlzSr">here</a>. Feedback and sugguestions are always welcome! ^ - ^
</div>
</article>

<p><b>Topics Covered:</b></p>
<ul>
<li>The GV Bound:</li>
<li>Efficiency and Maximum-Likelihood Decoding</li>
<li>Application: McEliece Cryptosystem</li>
<li>Off to Asymptopia<ul>
<li>Family of Codes</li>
<li>q-ary Entropy</li>
<li>Trade-off Between Rate and Distance</li>
</ul>
</li>
</ul>
<span id="more"></span>

<h1 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h1><p>In the <a href="/2024/12/16/stanford-cs250-ecc-lec2/" title="last lecture">last lecture</a>, we saw linear codes over a finite field in two linear-algebraic ways. As figured below, we can view a code as the column-span of a generator matrix and as the kernel of the parity-check matrix. There can be many different generator matrices and parity-check matrices for the same code.</p>
<img src="https://s21.ax1x.com/2024/12/26/pAvnIaD.png" alt="image.png" style="zoom:50%;" />

<p>Today, we are going to learn some useful things one can do with linear codes.</p>
<h1 id="The-GV-Bound"><a href="#The-GV-Bound" class="headerlink" title="The GV Bound"></a>The GV Bound</h1><p>In <a href="/2024/12/16/stanford-cs250-ecc-lec2/" title="Lecture 2">Lecture 2</a>, we explored the <strong>Hamming bound:</strong></p>
<p>$$<br>R\le 1 - \frac{\log_q\text{Vol}_q(\lfloor \frac{d-1}{2}\rfloor, n)}{n}<br>$$</p>
<p>which provides <u>an upper bound on the rate of code</u>. This bound highlights an <strong>impossible result</strong>, meaning that we <u>cannot construct a code with a large rate.</u></p>
<p>In contrast, the <strong>Gilbert-Varshamov (GV) bound</strong> offers a <strong>possible result</strong>. It demonstrates that <u>there exist codes with a decent rate.</u></p>
 <article class="message is-info"> <div class="message-header">  Gilber-Varshamov (GV) Bound:  </div> <div class="message-body">  For any <b>prime power</b> $q$, and for any $d\le n$, there exists a <b>linear</b> code $\mathcal{C}$ of length $n$, alphabet size $q$, distance $d$, and rate $$ R\ge 1 - \frac{\log_q {(\text{Vol}_q(d-1, n))-1}}{n} $$ Note: you can remove the words “prime power” and “linear” and the statements is till true.   </div> </article> 



<p>Aside from the fact that the GV bound provides a possibility result, another difference lies in the <u>quantity difference</u> in the $q$-ary volume of the Hamming ball.</p>
<p>We’ll explore the relationship between these two bounds later, but for now, keep in mind that the rate given by the GV bound must be less than that of the Hamming bound:</p>
<p>$$<br>R_{\text{GV}} &lt; R_{\text{Hamming}}<br>$$</p>
<p>otherwise, the math is broken.</p>
<p>Now, we’ll prove the GV bound — it’s pretty easy! </p>
<p><font color=blue><u><b><i>Proof of the GV Bound: </i></b></u></font></p>
<ul>
<li>The <strong>idea</strong> of the proof is to <u>choose a random linear code</u> $\mathcal{C}$ of specific dimension $k$, and show that <u>it has a distance at least $d$ with non-zero probability</u>—that is:</li>
</ul>
<p>$$<br>\text{Pr}[\mathcal{C} \text{ has distance}\ge d]&gt;0<br>$$</p>
<p>​    This implies that there exists a linear code with a decent rate.</p>
<article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>  This approach is known as the <b>Probabilisitic Method</b>. </div> </article>

<ul>
<li><p>Let $\mathcal{C}$ be a <strong>random subspace</strong> of $\mathbb{F}_q^n$ with <u>dimension</u> $k = n -\log_q(\text{Vol}_q(d-1, n))-1$.<br>If this code achieves a good distance, the $k/n$ basically <u>corresponds to the rate given in the GV bound.</u><br>This construction works because a linear code is essentially a linear space. Since there are finitely many subspaces of dimension $k$ in $\mathbb{F}_q^n$, we can uniformly sample a random linear subspace.</p>
</li>
<li><p>Let $G\in \mathbb{F}_q^{n\times k}$ be a <strong>random generator matrix</strong> for $\mathcal{C}$.<br>As discussed before, each code can have many generator matrices. We can uniformly sample one by selecting a random basis for the subspace and using it as the columns of the generator matrix.</p>
</li>
<li><p>Now, since the distance is the minimum weight of all non-zero codewords in the linear code, we have $\text{dist}(\mathcal{C})=\min_{c\in \mathcal{C}\backslash{0}}\text{wt}(c)=\min_{x\in \mathbb{F}_q^k\backslash{0}}\text{wt}(G\cdot x)$.</p>
</li>
<li><p><font color=blue><u><b>Useful Fact:</b></u></font><br>For any fixed $x\ne 0$, $G\cdot x$ is <u>uniformly random</u> in $\mathbb{F}_q^n\backslash{0}$. </p>
</li>
<li><p>For any given $x\ne 0$, using the useful fact, the <strong>probability that the weight</strong> of $G\cdot x$ is less than $d$ is equal to <u>the probability of a random non-zero codeword lying within the Hamming ball</u> centered at 0 with radius $d-1$. It is basically the volume of the Hamming ball divided by the volume of the whole space as indicated in the following second equality.</p>
</li>
</ul>
<p>$$<br>\begin{aligned}<br>\text{Pr}_G{\text{wt}(G\cdot x)&lt;d} &amp;= \text{Pr}_G{G\cdot x\in B_q(0, d-1)}\<br>&amp;= \frac{\text{Vol}_q(d-1, n)-1}{q^n-1}\<br>&amp;\le \frac{\text{Vol}_q(d-1, n)}{q^n}<br>\end{aligned}<br>$$</p>
<ul>
<li>By the union bound, we have</li>
</ul>
<p>$$<br>\text{Pr}{\exists x\in \mathbb{F}_q^k:\text{wt}(G\cdot x)&lt;d}\le q^k\cdot \frac{\text{Vol}_q(d-1, n)}{q^n}<br>$$</p>
<ul>
<li><p>The <strong>complement of this event</strong> is that $\forall x\in \mathbb{F}_q^k$ , $\text{wt}(G\cdot x)\ge d$, which <u>implies that the distance of the code is at least $d$.</u> </p>
</li>
<li><p>Thus, we win as long as this probability is <strong>strictly less than</strong> $1$, which guarantees the existence of a code with a good distance with non-zero probability.</p>
</li>
<li><p>Taking logs of both sides, we win if </p>
</li>
</ul>
<p>$$<br>k-n+\log_q(\text{Vol}_q(d-1, n))&lt;0<br>$$</p>
<ul>
<li>This is true since we precisely choose $k = n-\log_q(\text{Vol}_q(d-1, n))-1$ before. $\blacksquare$</li>
</ul>
<h1 id="Efficiency-amp-Maximum-Likelihood-Decoding"><a href="#Efficiency-amp-Maximum-Likelihood-Decoding" class="headerlink" title="Efficiency &amp; Maximum-Likelihood Decoding"></a>Efficiency &amp; <strong>Maximum-Likelihood Decoding</strong></h1><p>The GV bound tells us there exists good codes with decent rates.</p>
<p>Next, we are going to discuss the extent to which linear codes admit efficient algorithms.</p>
<p>We have the following efficient algorithms for linear codes to encode, detect errors and correct erasures:</p>
<ul>
<li><p><strong>Efficient Encoding:</strong><br>If $\mathcal{C}$ is linear, we have an efficient encoding map $x\mapsto G\cdot x$.<br>The computational cost is one matrix-vector multiplication.</p>
</li>
<li><p><strong>Efficient Error Detection:</strong><br>If $\mathcal{C}$ is linear with distance $d$, we can detect $\le d - 1$ errors efficiently:<br>If $0&lt; \text{wt}(e)\le d-1$ and $c\in \mathcal{C}$, then $H(c+e)=H\cdot e \ne 0$. Thus, we can just simply check if $H\tilde{c}=0$.</p>
</li>
<li><p><strong>Efficient Erasure Correction:</strong><br>If $\mathcal{C}$ is linear with distance $d$, we can correct $\le d-1$ erasures efficiently:<br><strong>Erasing bits in the codeword</strong> $c$ corresponds to <u>removing the corresponding rows of the generator matrix</u> $G$.</p>
  <img src="https://s21.ax1x.com/2024/12/26/pAvn2x1.png" alt="image.png" style="zoom:50%;" />

<p>The remaining $n-(d-1)$ rows form <u>a new linear system</u> $G’\cdot x = c’$. Since we know a code with distance $d$ can handle up to $d-1$ erasures (albeit with a non-efficient algorithm), there <u>must be exactly one $x$ that is consistent with this linear system</u>, and hence $G’$is full rank. The remaining task is to solve this linear system, which can be done with Gaussian elimination.</p>
  <img src="https://s21.ax1x.com/2024/12/26/pAvng2R.png" alt="image.png" style="zoom:50%;" />


</li>
</ul>
<p>The above is leaving out one important thing—<strong>correcting errors.</strong></p>
<p>We know how to correct errors in the $(7, 4, 3)_2$-Hamming code, but what about in general?</p>
<p>If $\mathcal{C}$ is linear with distance $d$, can we correct up to $\lfloor \frac{d-1}{2} \rfloor$ errors efficiently?</p>
<p>The bad news is no.</p>
<p>Consider the following problem. If we would solve this problem, we can correct up to $\lfloor \frac{d-1}{2} \rfloor$ errors. </p>
 <article class="message is-info"> <div class="message-header">  Maximum-Likelihood Decoding for Linear Codes:  </div> <div class="message-body">  Given $\tilde{c}\in \mathbb{F}_q^n$, and $G\in \mathbb{F}_q^{n\times k}$, find $x\in \mathbb{F}_q^k$ such that $\Delta(G\cdot x, \tilde{c})$ is minimized. Aka, find the codeword closest to a received word $\tilde{c}$.  </div> </article> 

<p>This problem (called <strong>Maximum-likelihood decoding for linear codes</strong>) <strong>is NP-hard</strong> in general [Berlekamp-McEliece-Van Tilborg 1978], even if the code is known in advance and you have an arbitrary amount of preprocessing time [Bruck-Noar 1990, Lobstein 1990]. It is even NP-hard to approximate (within a constant factor)! [Arora-Babai-Stern-Sweedyk 1993].</p>
<p>Even <strong>computing the minimum distance of linear codes is NP-hard</strong> given the generator matrix.</p>
<p>The take-away here is that <u>we are  unlikely to find a polynomial-time algorithm for this task.</u> This may sounds discouraging, but remember that <strong>NP-hardness is a worst-case condition</strong>. <u>While there exist linear codes that are probably hard to decode, but this does not imply that that all of them are.</u></p>
<p>Going forward, we will focus on designing codes that admit efficiently-decodable algorithms. Before that, let’s look at a <strong>cryptography application</strong> that leverages this decoding hardness.</p>
<h1 id="Application-McEliece-Cryptosystem"><a href="#Application-McEliece-Cryptosystem" class="headerlink" title="Application: McEliece Cryptosystem"></a>Application: McEliece Cryptosystem</h1><p>McEliece cryptosystem is a public-key scheme based on the decoding hardness of binary linear codes.</p>
<p>Suppose that Alice and Bob want to talk securely. Now there is no noise, just an Eavesdropper Eve. </p>
<img src="https://s21.ax1x.com/2024/12/26/pAvnhqK.png" alt="image.png" style="zoom:40%;" />

<p>In public key cryptography, everyone has a public key and a private key. To send a message to Bob, Alice encrypts it using Bob’s public key. Bob decodes it with his private key. We hope this process is secure as long as Bob’s private key stays private.</p>
<p>The <strong>McEliece Cryptosystem</strong> consists of three main algorithms:</p>
<ul>
<li><p><strong>Generate Private and Public Keys</strong></p>
<ol>
<li><p>Bob chooses $G\in \mathbb{F}_2^{n\times k}$, the generator matrix for an (appropriate) binaray linear code $\mathcal{C}$ that is efficiently decodable from $t$ errors.</p>
 <article class="message message-immersive is-warning"> <div class="message-body"> <i class="fas fa-exclamation-triangle mr-2"></i> Not all codes work for McEliece crytosystem; the chosen code at least must be efficiently decodable. In particular, McEliece cryptosystem uses a binary “<b>Goppa Code</b>”. </div> </article> 
</li>
<li><p>Bob chooses a random invertible $S\in \mathbb{F}_2^{k\times k}$ and a random permutation matrix $P\in \mathbb{F}_2^{n\times n}$. The permutation matrix $P$ has exactly one 1 in each column such that $Px$ permutes the coordinates of the vector $x$.</p>
</li>
<li><p>Bob’s private key is $(S, G, P)$.</p>
</li>
<li><p>Bob’s public key consists of $\hat{G}=PGS$ and the parameter $t$.</p>
</li>
</ol>
</li>
<li><p><strong>Encrypt with Bob’s Public key</strong><br>To send a message $x\in \mathbb{F}_2^k$ to Bob:</p>
<ol>
<li>Alice chooses a random vector $e\in \mathbb{F}_2^n$ with $\text{wt}(e)=t$.</li>
<li>Alice sends $\hat{G}x+e$ to Bob.</li>
</ol>
</li>
<li><p><strong>Decrypt with Bob’s Private Key</strong><br>To decrypt the message $G’x+e$:</p>
<ol>
<li><p>Bob computes $P^{-1}(\hat{G}x+e)=GSx + P^{-1} e =G(Sx) +e’$, where $\text{wt}(e’)=t$.</p>
<p>At this point, we write it as <u>a corrupted codeword</u> $G(Sx)+e’$ with exactly $t$ errors since the permutation matrix $P^{-1}$ only permutes the coordinates of $e$. Bob can use the fact that $G$ is the generator matrix for a code that is efficiently able to correct up to $t$ errors.</p>
</li>
<li><p>Bob uses the efficient decoding algorithm to recover $Sx$.</p>
</li>
<li><p>Bob can compute $x = S^{-1}\cdot Sx$.</p>
</li>
</ol>
</li>
</ul>
<p>Why might this be secure?</p>
<p>Suppose Eve sees $\hat{G}x+e$ and she knows $G’$ and $t$. Hence, this problem is <u>the same as decoding the code</u> $\hat{C}={\hat{G}x : x\in \mathbb{F}_2^k}$ from $t$ errors. </p>
<p>The <strong>security</strong> of the McEliece crytosystem relies the following assumptions:</p>
<ol>
<li><strong>The public key $\hat{G}$ looks random</strong>: By scrambling $G$ with $S$ and $P$, it is difficult for Eve to distinguish $\hat{G}$ from a random generator matrix.</li>
<li><strong>Decoding a random linear code is computationally hard:</strong>  While decoding the worst-case code is NP-hard, it is not too much of stretch that decoding a random linear code is also hard on average.</li>
</ol>
<p>If these assumptions hold true, decoding the code $\hat{C}={\hat{G}x : x\in \mathbb{F}_2^k}$ from $t$ errors is computationally hard for Eve.</p>
<p>This assumption that “Decoding $\hat{G}x+e$ is hard” (for an appropriate choice of $G$) is called the McEliece Assumption. Some people believe it and some don’t.</p>
 <article class="message message-immersive is-warning"> <div class="message-body"> <i class="fas fa-exclamation-triangle mr-2"></i>  “Decoding $\hat{G}x+e$ is hard for Eve” is <b>NOT</b> the same as “Maximum likelihood decoding of linear codes is NP-hard”. <br>There are two main differences: <br>First, we have some promise that there were $\le  t$ errors in McEliece assumption.  <br>Second, <b>NP-harness is a worst-case assumption</b>. For cryptography, we need an average-case assumption.  </div> </article> 



 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>   <b>Worst-case vs. Average-case:</b><br> Worst-case: The problem is considered hard on worst-case if it is difficult to solve for the most difficult case. If a solution is found for the worst-case instance, the problem is solvable for all instances, e.g. $P\ne NP$. <br><br>Average-case: The problem is considered hard if it is difficult to solve for a randomly chosen instance. This assumes that solving the problem is computationally hard for the “average” case rather than just the hardest instance. <br><br>In cryptography, <b>average-case hardness</b> is more relevant because security relies on the assumption that attackers cannot efficiently solve a typical random instance of the underlying problem (e.g., decoding a random linear code or factoring a randomly chosen large integer).  </div> </article> 

<h1 id="Off-to-Asymptopia"><a href="#Off-to-Asymptopia" class="headerlink" title="Off to Asymptopia"></a>Off to Asymptopia</h1><p>So far, we’ve seen the optimal rate  for a code with distance $d$ and $|\Sigma|=q$ is bounded above by the Hamming bound and bounded below by the GV bound.</p>
<p>$$<br>1-\frac{1}{n}\cdot \log_q (\text{Vol}_q(d-1, n))\le k/n \le 1 - \frac{1}{n} \cdot \log_q(\text{Vol}_q(\left\lfloor \frac{d-1}{2}\right \rfloor, n)<br>$$</p>
<p>Recall the <strong>combinational question</strong> we posed in <a href="/2024/12/11/stanford-cs250-ecc-lec1/" title="Lecture 1">Lecture 1</a>:</p>
<p><font color=red> <b>What is the best trade-off between rate and distance?</b></font></p>
<p>To address this in the asymptotical setting, we are going to think about the following limiting <strong>parameter regime</strong>: $n, k, d\rightarrow \infty$ so that the rate $k/n$ and the relative distance $\delta$ approaches constants.</p>
<img src="https://s21.ax1x.com/2024/12/26/pAvncG9.png" alt="image.png" style="zoom:50%;" />



<p>The <strong>motivations</strong> for this parameter regime:</p>
<ol>
<li>It will allow us to better understand what’s possible and what’s not.</li>
<li>In many applications, $n, k, d$ are pretty large and $R, \delta$ are the things we want to be thinking about.</li>
<li>It will let us talk meaningfully about computational complexity.</li>
</ol>
<h2 id="Family-of-Codes"><a href="#Family-of-Codes" class="headerlink" title="Family of Codes"></a>Family of Codes</h2><p>Before that, let’s define a family of codes.</p>
 <article class="message is-info"> <div class="message-header">  A Family of Codes  </div> <div class="message-body">  A family of codes is a collection $\mathcal{C}=\{\mathcal{C}_i\}_{i=1}^{\infty}$, where $\mathcal{C}_i$ is an $(n_i, k_i, d_i)_{q_i}$ code. Given such a family of codes, we can define the rate and the relative distance: The <b>rate</b> of $\mathcal{C}$ is $R(\mathcal{C})=\lim_{i\to \infty} k_i/n_i$. The <b>relative distance</b> of $\mathcal{C}$ is $\delta{(\mathcal{C}})=\lim_{i\to \infty} d_i /n_i$.  </div> </article> 



 <article class="message message-immersive is-warning"> <div class="message-body"> <i class="fas fa-exclamation-triangle mr-2"></i>  We will frequently abuse notation and refer to $\mathcal{C}$ as a “code”, and we’ll drop the subscript $i$ and just think about $n, k, d\to \infty$  </div> </article> 

<p>Now, let’s look at an example of a family of codes—<strong>Hamming codes.</strong></p>
The $i$-th code $\mathcal{C}_i$ is a $(2^i-1, 2^i-i-1, 3)_2$ code so $\mathcal{C}=\{\mathcal{C}_i\}_{i=1}^\infty$ represents a family of codes.

 $\mathcal{C}_i$ is defined by its parity-check matrix, where the columns corresponds to the binary vector representations of all non-zero elements of $\mathbb{F}_{2^i}$. 

<img src="https://s21.ax1x.com/2024/12/26/pAvn6PJ.png" alt="image.png" style="zoom:60%;" />

<p>The <u>rate</u> of this family is: </p>
<p>$$<br>\lim_{i\to \infty }\frac{2^i-i-1}{2^i-1}=1<br>$$</p>
<p>This rate approaches to 1, which is a very good rate.</p>
<p>However, the <u>relative distance</u> is:</p>
<p>$$<br>\lim_{i\to \infty}\frac{3}{2^i-1}=0<br>$$</p>
<p>Hence, in the asymptotic setting, our question is: for any family of a code,</p>
<p><font color=red><b>What is the best trade-off between $R(\mathcal{C})$ and $\delta{(\mathcal{C})}$?</b></font></p>
<p>As we see in the family of Hamming codes, we cannot achieve good trade-off between rate and distance. While it has a phenomenal rate, its distance is poor.</p>
<p>An easier question to ask is:</p>
<p><font color=red><b>Can we obtain codes with $R(\mathcal{C})&gt;0$ and $\delta{(\mathcal{C})}&gt;0$?</b></font></p>
<p>We define a family of codes with the rate $R(\mathcal{C})&gt;0$ and relative distance $\delta(\mathcal{C})&gt;0$ (both strictly greater than 0) as <font color=red>asymptotically good</font>.</p>
<h2 id="q-ary-Entropy"><a href="#q-ary-Entropy" class="headerlink" title="q-ary Entropy"></a>q-ary Entropy</h2><p>Now we have an asymptotic parameter regime, how should we parse the GV and Hamming bounds? In particular, what do these bounds look like in terms of $\delta$?</p>
<p>$$<br>1-\frac{1}{n}\cdot \log_q (\text{Vol}_q(d-1, n))\le R(\mathcal{C}) \le 1 - \frac{1}{n} \cdot \log_q(\text{Vol}_q(\left\lfloor \frac{d-1}{2}\right \rfloor, n)<br>$$</p>
<p>We know that $\text{Vol}_q(\lfloor \frac{d-1}{2} \rfloor, n)=\sum_{j=0}^{\lfloor {d-1\over 2}\rfloor}{n\choose j}(q-1)^j$ but this expression is not very helpful for analysis. </p>
<p>To address this, we use the <strong>$q$-ary entropy function,</strong> which provides a concise way to <u>capture the volume of Hamming balls.</u></p>
 <article class="message is-info"> <div class="message-header">  q-ary Entropy Function:  </div> <div class="message-body">  The q-ary entropy function $H_q:[0,1]\to [0, 1]$ is defined as:  $$ H_q(x)=x\log_q(q-1)-x\log_q(x)-(1-x)\log_q(1-x) $$ This generalizes the binary entropy function $H_2(x)=-x\log x - (1-x)\log (1-x)$.  </div> </article> 



<p>Using q-ary entropy function, we can bound the volume of the Hamming ball with the following propositions, allowing us to replace the pesky volume expression with cleaner approximations.</p>
<p> <font color=blue><u><b>Propositions:</b></u></font>  </p>
<p>Let $q\ge 2$ be an integer, and let $0\le p \le 1 - {1\over q}$. Then:</p>
<ul>
<li>$\text{Vol}_q(pn, n)\le q^{n\cdot H_q(p)}$ </li>
<li>$\text{Vol}_q(pn, n)\ge q^{n\cdot H_q(p) - o(n)}$  </li>
</ul>
<p>Here, the $o(n)$ term is a function $f(n)$ such that $\lim_{n\to \infty}{f(n)\over n}\to 0$. We can consider this term as negligible compared to $n\cdot H_q(p)$.</p>
 <article class="message message-immersive is-primary"> <div class="message-body"> <i class="fas fa-info-circle mr-2"></i>   <b>Intuitive Interpretation of q-ary entropy:</b> <br> The binary entropy function $H_2(p)$ is often described in terms of the number of bits needed to describe something. For example, a random string of length $n$, where each bit is 1 with probability $p$, can be described using  $n\cdot H_2(p)$ bits. <br><br>There is a similar interpretation for $q$-ary entropy. Suppose we choose $x\in \mathbb{F}_q^n$ s.t. each $x_i$ is 0 with probability $1-p$ and random in $\mathbb{F}_q^*$ with probability $p$. $$ x_i=\begin{cases}0 &\text{w/ prob. }1-p\\\text{random in }\mathbb{F}_q^* &\text{w/ prob. }p\end{cases} $$ <br>Then, the number of bits needed to describe $x$ is roughly $n\cdot H_2(p)$.  </div> </article> 



<p>Before proceeding, let’s examine how this q-ary entropy function behaves.</p>
<img src="https://s21.ax1x.com/2024/12/26/pAvnWKx.png" alt="image.png" style="zoom:50%;" />

<ul>
<li>$H_2(x)$: This function is 0 at $x=0$ and $x=1$, with a maximum value of $1$ at $x={1\over 2}$.</li>
<li>$H_3(x)$: It resembles $H_2(x)$ but is slightly shoved over to the right. It’s maximum value occurs at $x={2\over 3}$.</li>
<li>$H_6(x)$: This function is shifted further to the right, with its maximum value occurring at $x=\frac{5}{6}$.</li>
<li>More generally, $H_q(x)$ has the maximum value of $1$ at $x={q-1\over q}$. As $q$ increases, curve of the function is shoved more and more over to the right.</li>
</ul>
<p>Here are some useful properties of $H_q(x)$:</p>
<ul>
<li><p>If $p\in [0, 1]$ is constant and $q\to \infty$, then</p>

  $$
    H_q(p)= \underbrace{p\cdot \log_q(q-1)}_{\text{basically 1}}+\underbrace{O(\log_q(\text{stuff}))}_{\text{really small}}\approx p
  $$
  
    
<p>  So, eventually the plot looks like a line of $H_q(p)=p$ and a little hicky at the end.</p>
  <img src="https://s21.ax1x.com/2024/12/26/pAvnfr6.png" alt="image.png" style="zoom:100%;" />
</li>
<li><p>If $q$ is constant and $p\to 0$, then</p>

  $$
    \begin{align}
    H_q(p)&=\underbrace{p\cdot \log_q(q-1)}_{O(p)}+\underbrace{p\log_q\left({1\over p}\right)}_{\text{This term is the largest}}+
    \underbrace{(1-p)\log_q\left({1\over 1-p}\right )}_{\approx p/\ln(q) =O(p)}\\
    &\approx p\log_q\left({1\over p}\right)
    \end{align}
  $$
  
    
<p>  So, near the origin, all those curves look like $x\ln(1/x)\over \ln q$.</p>
</li>
</ul>
<article class="message message-immersive is-warning">  <div class="message-body">  <i class="fas fa-exclamation-triangle mr-2"></i> The following is my <strong>own analysis</strong> for the last term $(1-p)\cdot \log_q\left ({1\over 1-p}\right)$ using Taylor expansion. </div>  </article>

<p><font color=blue><u><b><i>Analyze the last term using Taylor expansions: </i></b></u></font></p>
<ul>
<li><p>The Taylor expansion of $f(x)$ at $x=a$ is</p>
<p>  $$<br>  \begin{align}<br>  f(x)&amp;=\sum_{n = 0}^\infty\frac{f^{(n)}(a)}{n!}(x-a)^n \<br>  &amp;=f(a)+f’(a)\cdot (x-a)+\frac{f’’(a)}{2!}\cdot (x-a)^2+\dots<br>  \end{align}<br>  $$</p>
</li>
<li><p>Derivatives of $\ln (x)$ are given as: $\ln’(x)=x^{-1}$, $\ln^{‘’}(x)=(-1)\cdot x^{-2}$, $\ln^{(3)}=(-1)\cdot (-2)\cdot x^{-3}$. By deduction, we have:  $\ln^{(n)}(x)=(-1)^{n-1}\cdot (n-1)!\cdot x^{-n}$.</p>
</li>
<li><p>The Taylor expansion of $\ln(x)$ at $x=1$ is:</p>
<p>  $$<br>  \begin{align}<br>  \ln(x) &amp;= \ln(1)+\sum_{n=1}^{\infty} \frac{\ln^{n}(1)}{n!}\cdot (x-1)^n\&amp;=\sum_{n=1}^{\infty}(-1)^{n-1}\cdot {1\over n}\cdot (x-1)^n\<br>  &amp;=(x-1) -{(x-1)^2\over 2}+{(x-1)^3\over 3}-\dots+{(-1)^{n-1}\over n}\cdot (x-1)^n<br>  \end{align}<br>  $$</p>
</li>
<li><p>Applying this expansion to the last term:</p>
<p>  $$<br>  \begin{align}<br>  \log_q\left ({1\over 1-p}\right)&amp;=-{\ln (1-p) \over \ln q}\<br>  &amp;=-{1\over \ln q}\cdot [(-p)-\frac{(-p)^2}{2}+\dots]\<br>  &amp;\approx {1\over \ln q}\cdot p<br>  \end{align}<br>  $$</p>
</li>
<li><p>This shows that $\lim_{p\to 0}(1-p)\cdot \log_q\left ({1\over 1-p}\right)\approx p/\ln (q)=O(p)$</p>
</li>
</ul>
<hr>
<p>Now, we can use them to <u>simplify our expression for GV and Hamming bounds</u>, both involving the the volume of the q-ary Hamming ball. The strategy is to take log base $q$ of the following approximation in terms of the $\delta$:</p>
<p>$$<br>\text{Vol}_q(\delta n, n)\approx q^{n\cdot H_q(\delta)}<br>$$</p>
<p>We can replace the pesky term $\log_q \text{Vol}_q(\delta n,n)$ with $n\cdot H_q(\delta)$.</p>
 <article class="message is-info"> <div class="message-header">  Hamming Bound:  </div> <div class="message-body">  For any family $\mathcal{C}$ of the q-ary codes, we have $$ R(\mathcal{C})\le 1 - H_q(\delta{\mathcal{(C)}}/2) $$  </div> </article> 



<p><strong>GV Bound:</strong></p>
 <article class="message is-info"> <div class="message-header">  GV Bound:  </div> <div class="message-body">  Let $q\ge 2$. For any $0\le \delta\le 1- \frac{1}{q}$, and for any $0< \epsilon \le 1 - H_q(\delta)$, there exists a q-ary family of codes $\mathcal{C}$ with $\delta(\mathcal{C})\ge \delta$ and  $$ R(\mathcal{C})\ge 1 - H_q(\delta)-\epsilon $$   </div> </article> 

<h2 id="Trade-off-Between-Rate-and-Distance"><a href="#Trade-off-Between-Rate-and-Distance" class="headerlink" title="Trade-off Between Rate and Distance"></a>Trade-off Between Rate and Distance</h2><p>Now, it’s easier to compare these two bounds:</p>
<p>The following plot the trade-off for $q=2$ in terms of only the rate $R$ and the relative distance $\delta$, without considering $n, k, d$.</p>
<img src="https://s2.loli.net/2024/12/26/wj7O5mn6hkHJPZQ.png" alt="image.png" style="zoom:50%;" />

<ul>
<li>The <font color=red>red line</font> represents the Hamming bound for binary codes.<br>Notably,  <strong>no point above the Hamming bound is achievable</strong> by any binary codes.</li>
<li>The <font color=blue>blue line</font> represents the GV bound for binary codes.<br>Notably,  <strong>any point below the GV bound is achievable</strong> by some codes.</li>
<li>The <font color=yellow>yellow region</font> is an area of <strong>uncertainty</strong>.</li>
<li>We would like to push the GV bound as much up as possible while at the same time try and push down the Hamming bound as much as possible.</li>
</ul>
<p>Note that the GV bound answers our earlier question:</p>
<p> <strong>There do exist asymptotic good codes!</strong></p>
<p>But, can we find some explicit ones with efficient algorithms?</p>
<p>Regarding the yellow uncertain region, there are <strong>several other interesting questions:</strong></p>
<ul>
<li><font color=red><b> Are there family of codes that beat the GV bound? </b></font><br>The answer is both yes and no.<ul>
<li>Answer 1: Yes. For $q=49$, “Algebraic Geometry Codes” beat the GV bound.</li>
<li>Answer 2: For <strong>binary codes</strong>, we don’t know.<br>This remains an <font color=red><b> OPEN QUESTION! </b></font> The GV bound (which is relatively straighforward to prove) is the best-known possibility of result we have for binary codes.</li>
</ul>
</li>
<li><font color=red><b> Can we find explicit constructions of families of codes that meet the GV bound? </b></font><br>Recall that our <strong>proof for GV bound is non-constructive;</strong> it uses the probabilistic method to show the existence of a random linear codes with decent rates. However, we are looking for  explicit descriptions or efficient algorithms to construct such codes.<ul>
<li>Answer 1: Yes, for large alphabet. (We’ll see soon)</li>
<li>Answer 2: For <strong>binary codes</strong>, recent work [Ta-Shma 2017] gives something close in a very particular parameter regime…but in general, it’s still an <font color=red><b> OPEN QUESTION! </b></font></li>
</ul>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>「Algebraic ECCs」: Lec3 GV Bound and q-ARY Entropy</p><p><a href="https://f7ed.com/2024/12/25/stanford-cs250-ecc-lec3/">https://f7ed.com/2024/12/25/stanford-cs250-ecc-lec3/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>f7ed</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-12-26</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-12-26</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="icons" rel="noopener" target="_blank" title="Share Alike" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-sa"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Cryptography/">Cryptography, </a><a class="link-muted" rel="tag" href="/tags/ECC/">ECC, </a><a class="link-muted" rel="tag" href="/tags/GV-Bound/">GV Bound, </a><a class="link-muted" rel="tag" href="/tags/q-ary-Entropy/">q-ary Entropy </a></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/qrcode_wechat.jpg" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/f7ed" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/qrcode_alipay.jpg" alt="Alipay"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/01/12/stanford-cs250-ecc-lec4/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">「Algebraic ECCs」: Lec4 Singleton + Plotkin Bounds and RS Code</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/12/15/stanford-cs250-ecc-lec2/"><span class="level-item">「Algebraic ECCs」: Lec2 Linear Codes and Finite Fields</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "33add0aeeac4f0167d7930ecde4e414e",
            repo: "f7ed.github.io",
            owner: "f7ed",
            clientID: "ec59f5258ac0ec443907",
            clientSecret: "f092b308c3e1b46327481c3547ee0dd7fc1bda10",
            admin: ["f7ed"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "en",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/profile.png" alt="f7ed"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">f7ed</p><p class="is-size-6 is-block">热爱可抵漫长岁月。</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">71</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">139</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="mailto:f7edliu@outlook.com" target="_blank" rel="noopener">Email me</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/f7ed"><i class="fab fa-github"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Recap"><span class="level-left"><span class="level-item">1</span><span class="level-item">Recap</span></span></a></li><li><a class="level is-mobile" href="#The-GV-Bound"><span class="level-left"><span class="level-item">2</span><span class="level-item">The GV Bound</span></span></a></li><li><a class="level is-mobile" href="#Efficiency-amp-Maximum-Likelihood-Decoding"><span class="level-left"><span class="level-item">3</span><span class="level-item">Efficiency &amp; Maximum-Likelihood Decoding</span></span></a></li><li><a class="level is-mobile" href="#Application-McEliece-Cryptosystem"><span class="level-left"><span class="level-item">4</span><span class="level-item">Application: McEliece Cryptosystem</span></span></a></li><li><a class="level is-mobile" href="#Off-to-Asymptopia"><span class="level-left"><span class="level-item">5</span><span class="level-item">Off to Asymptopia</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Family-of-Codes"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Family of Codes</span></span></a></li><li><a class="level is-mobile" href="#q-ary-Entropy"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">q-ary Entropy</span></span></a></li><li><a class="level is-mobile" href="#Trade-off-Between-Rate-and-Distance"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">Trade-off Between Rate and Distance</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/f1ed_logo.png" alt="fred&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 f7ed</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent " target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="f7ed&#039;s GitHub" href="https://github.com/f7ed"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script>
      var sc_project=12961083;
      var sc_invisible=1;
      var sc_security="ad3fb575";
      var sc_https=1;
      var sc_remove_link=1;</script><script src="https://www.statcounter.com/counter/counter.js" async></script><noscript><div class="statcounter"><img class="statcounter" src="https://c.statcounter.com/12961083/0/ad3fb575/1/" alt="real time web analytics"></div></noscript><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>